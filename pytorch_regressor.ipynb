{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "696b7d6f-73e2-47c9-89bc-0fde7c82592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ting Jiang teaches:\n",
      "['CMSC351', 'CMSC417']\n",
      "\n",
      "Larry Herman teaches:\n",
      "['CMSC102', 'CMSC132', 'CMSC132H', 'CMSC216', 'CMSC330']\n",
      "\n",
      "Maksym Morawski teaches:\n",
      "['BIOI602', 'CMSC106', 'CMSC250', 'CMSC320', 'CMSC351', 'CMSC398P', 'CMSC421', 'DATA320', 'DATA602', 'MSML602']\n",
      "\n",
      "Ilchul Yoon teaches:\n",
      "['BMGT302', 'BMGT402', 'CMSC106', 'CMSC122', 'CMSC131', 'CMSC132', 'CMSC216', 'CMSC335', 'CMSC389N', 'CMSC411']\n",
      "\n",
      "Allan Yashinski teaches:\n",
      "['CMSC456', 'ENEE456', 'HLTH710', 'MATH141H', 'MATH240', 'MATH241H', 'MATH401', 'MATH402', 'MATH403', 'MATH405', 'MATH406', 'MATH423', 'MATH436', 'MATH456', 'MATH461', 'MATH462', 'MATH463']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "BASE_URL = \"https://planetterp.com/api/v1\"\n",
    "\n",
    "professors = [\n",
    "    \"Ting Jiang\",\n",
    "    \"Larry Herman\",\n",
    "    \"Maksym Morawski\",\n",
    "    \"Ilchul Yoon\",\n",
    "    \"Allan Yashinski\",\n",
    "]\n",
    "\n",
    "def get_course(name: str, reviews: bool = False):\n",
    "    params = {\n",
    "        \"name\": name,\n",
    "        \"reviews\": str(reviews).lower()\n",
    "    }\n",
    "    r = requests.get(f\"{BASE_URL}/professor\", params=params)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "for prof in professors:\n",
    "    data = get_course(prof)\n",
    "\n",
    "    # remove duplicates by converting to a set, then back to a list for printing\n",
    "    unique_courses = sorted(set(data.get(\"courses\", [])))\n",
    "\n",
    "    print(prof, \"teaches:\")\n",
    "    print(unique_courses)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a338100d-b450-47ab-a16f-be8022603e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ting Jiang: retrieved 26 reviews\n",
      "Larry Herman: retrieved 336 reviews\n",
      "Maksym Morawski: retrieved 247 reviews\n",
      "Ilchul Yoon: retrieved 175 reviews\n",
      "Allan Yashinski: retrieved 93 reviews\n"
     ]
    }
   ],
   "source": [
    "professor_reviews = {}\n",
    "\n",
    "for prof in professors:\n",
    "    data = get_course(prof, reviews=True)\n",
    "    professor_reviews[prof] = data.get(\"reviews\", [])\n",
    "    print(f\"{prof}: retrieved {len(professor_reviews[prof])} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5014748e-dc2a-4ac3-aebd-581e33254057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           professor   course  \\\n",
      "0         Ting Jiang  CMSC351   \n",
      "1         Ting Jiang     None   \n",
      "2         Ting Jiang  CMSC351   \n",
      "3         Ting Jiang  CMSC351   \n",
      "4         Ting Jiang  CMSC351   \n",
      "..               ...      ...   \n",
      "872  Allan Yashinski  MATH405   \n",
      "873  Allan Yashinski  MATH461   \n",
      "874  Allan Yashinski  CMSC456   \n",
      "875  Allan Yashinski  MATH461   \n",
      "876  Allan Yashinski  MATH401   \n",
      "\n",
      "                                                review  rating expected_grade  \n",
      "0    Ting is an ok lecturer but i always found myse...       4             A-  \n",
      "1    bad lecturer decent exams saved by justin's no...       3             A-  \n",
      "2    Ting is an okay lecturer and a nice person. Sh...       4             B+  \n",
      "3    She's a pretty boring and unhelpful lecturer, ...       3              B  \n",
      "4    Setting aside the co-teaching with Justin, Tin...       2             A-  \n",
      "..                                                 ...     ...            ...  \n",
      "872  Allan for MATH405 is not my most recommended p...       4             B+  \n",
      "873  He's a great lecturer; he really explains conc...       5             B+  \n",
      "874  Allan is an awesome professor. Great lectures,...       4              B  \n",
      "875  Allan is the goat. I find his lectures to be e...       5              A  \n",
      "876  This is a very engaging and well-structured cl...       4                 \n",
      "\n",
      "[877 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# move fetched data into a dataframe\n",
    "rows = []\n",
    "for prof, reviews in professor_reviews.items():\n",
    "    for r in reviews:\n",
    "        rows.append({\n",
    "            \"professor\": prof,\n",
    "            \"course\": r.get(\"course\"),\n",
    "            \"review\": r.get(\"review\"),\n",
    "            \"rating\": r.get(\"rating\"),\n",
    "            \"expected_grade\": r.get(\"expected_grade\"),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4122deb-8da0-420d-b29d-e9d6080ad6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           professor   course  \\\n",
      "0         Ting Jiang  CMSC351   \n",
      "1         Ting Jiang     None   \n",
      "2         Ting Jiang  CMSC351   \n",
      "3         Ting Jiang  CMSC351   \n",
      "4         Ting Jiang  CMSC351   \n",
      "..               ...      ...   \n",
      "872  Allan Yashinski  MATH405   \n",
      "873  Allan Yashinski  MATH461   \n",
      "874  Allan Yashinski  CMSC456   \n",
      "875  Allan Yashinski  MATH461   \n",
      "876  Allan Yashinski  MATH401   \n",
      "\n",
      "                                                review  rating expected_grade  \n",
      "0    Ting is an ok lecturer but i always found myse...       4             A-  \n",
      "1    bad lecturer decent exams saved by justin's no...       3             A-  \n",
      "2    Ting is an okay lecturer and a nice person. Sh...       4             B+  \n",
      "3    She's a pretty boring and unhelpful lecturer, ...       3              B  \n",
      "4    Setting aside the co-teaching with Justin, Tin...       2             A-  \n",
      "..                                                 ...     ...            ...  \n",
      "872  Allan for MATH405 is not my most recommended p...       4             B+  \n",
      "873  He's a great lecturer; he really explains conc...       5             B+  \n",
      "874  Allan is an awesome professor. Great lectures,...       4              B  \n",
      "875  Allan is the goat. I find his lectures to be e...       5              A  \n",
      "876  This is a very engaging and well-structured cl...       4           <NA>  \n",
      "\n",
      "[876 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# replace empty strings with NaN\n",
    "df.replace(\"\", pd.NA, inplace = True)\n",
    "\n",
    "# drop rows with missing values\n",
    "df_clean = df.dropna(subset = [\"review\", \"rating\"])\n",
    "\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d10e952c-3ea5-4313-8bc4-0ada523c8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, grade_to_index, max_len = 256):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.grade_to_index = grade_to_index\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # maps letter grade to numerical value\n",
    "        row = self.df.iloc[index]\n",
    "        text = row[\"review\"]\n",
    "        grade = row[\"expected_grade\"] if pd.notna(row[\"expected_grade\"]) else \"Unknown\"\n",
    "        grade_index = self.grade_to_index[grade]\n",
    "\n",
    "        # converts numerical value to tensor\n",
    "        rating = torch.tensor(float(row[\"rating\"]), dtype = torch.float)\n",
    "\n",
    "        # tokenizes review text\n",
    "        tokens = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation = True,\n",
    "            max_length = self.max_len,\n",
    "            return_tensors = \"pt\",\n",
    "        )\n",
    "        \n",
    "        # one hot encode expected grade\n",
    "        grade_onehot = torch.nn.functional.one_hot(\n",
    "            torch.tensor(grade_index),\n",
    "            num_classes = len(self.grade_to_index)\n",
    "        ).float()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": tokens[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": tokens[\"attention_mask\"].squeeze(),\n",
    "            \"grade\": grade_onehot,\n",
    "            \"rating\": rating,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d30e5435-8fef-4c6e-827f-ec31a2fd20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel\n",
    "\n",
    "class RatingRegressor(torch.nn.Module):\n",
    "    def __init__(self, num_grades):\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "        # 768 dimensional embedding\n",
    "        hidden_size = 768\n",
    "\n",
    "        # regression to predict rating\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size + num_grades, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, grade):\n",
    "\n",
    "        # run text through bert\n",
    "        bert_out = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n",
    "\n",
    "        # embedding representing meaning of sentence\n",
    "        cls = bert_out.last_hidden_state[:, 0]\n",
    "\n",
    "        # return as a 1D tensor\n",
    "        x = torch.cat([cls, grade], dim = 1)\n",
    "        out = self.regressor(x)\n",
    "        return out.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d998510d-2b5b-446f-add1-d868098f424b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Training loss: 3.52424\n",
      "Epoch 2 : Training loss: 1.61950\n",
      "Epoch 3 : Training loss: 0.65728\n",
      "Epoch 4 : Training loss: 0.31405\n",
      "Epoch 5 : Training loss: 0.18644\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# convert letter grades to numerical values\n",
    "all_grades = sorted(df_clean[\"expected_grade\"].fillna(\"Unknown\").unique().tolist())\n",
    "grade_to_index = {g: i for i, g in enumerate(all_grades)}\n",
    "num_grades = len(all_grades)\n",
    "\n",
    "# split data 80/20\n",
    "train_df, test_df = train_test_split(df_clean, test_size=0.2)\n",
    "train_ds = ReviewDataset(train_df, tokenizer, grade_to_index=grade_to_index)\n",
    "test_ds  = ReviewDataset(test_df, tokenizer, grade_to_index=grade_to_index)\n",
    "\n",
    "# create batches\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=8)\n",
    "\n",
    "# build model\n",
    "model = RatingRegressor(num_grades=num_grades).to(device)\n",
    "\n",
    "# updates weights based on gradient\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "# MSE loss\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# five training loops\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(\n",
    "            batch[\"input_ids\"].to(device),\n",
    "            batch[\"attention_mask\"].to(device),\n",
    "            batch[\"grade\"].to(device)\n",
    "        )\n",
    "\n",
    "        loss = criterion(pred, batch[\"rating\"].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} : Training loss: {total_loss / len(train_loader):.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c6bb8ec-5947-4aa9-9764-905362c2d622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.5999168\n",
      "Test RMSE: 0.774543\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "true = []\n",
    "\n",
    "# collects predicted and true ratings\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        prediction = model(\n",
    "            batch[\"input_ids\"].to(device),\n",
    "            batch[\"attention_mask\"].to(device),\n",
    "            batch[\"grade\"].to(device),\n",
    "        )\n",
    "\n",
    "        predictions.extend(prediction.cpu().numpy())\n",
    "        true.extend(batch[\"rating\"].cpu().numpy())\n",
    "\n",
    "mse = np.mean((np.array(predictions) - np.array(true))**2)\n",
    "print(\"Test MSE:\", mse)\n",
    "print(\"Test RMSE:\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1542fcb-ad14-442a-8c36-0a5ee2189bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                review  predicted_rating  \\\n",
      "0    This was genuinely one of my favorite courses ...          5.043595   \n",
      "1    Maksym did a fantastic job with this course an...          4.960024   \n",
      "2    Max is goated idc what the other reviews say. ...          4.524414   \n",
      "3    Yoon's class is really keeping me on my toes. ...          2.356693   \n",
      "4    bro pick anybody, not him. When he explains th...          1.455905   \n",
      "..                                                 ...               ...   \n",
      "171  This professor has been THE LEAST accomodating...          1.293905   \n",
      "172  Take it with someone else if you actually want...          2.182126   \n",
      "173  Great instructor. Explains difficult concepts ...          5.036975   \n",
      "174  Definitely try to avoid him. \\r\\n\\r\\nHis lectu...          1.927685   \n",
      "175  Really good professor. He's great at teaching,...          4.628873   \n",
      "\n",
      "     true_rating    off_by  \n",
      "0            5.0  0.043595  \n",
      "1            5.0  0.039976  \n",
      "2            5.0  0.475586  \n",
      "3            5.0  2.643307  \n",
      "4            1.0  0.455905  \n",
      "..           ...       ...  \n",
      "171          1.0  0.293905  \n",
      "172          1.0  1.182126  \n",
      "173          5.0  0.036975  \n",
      "174          2.0  0.072315  \n",
      "175          5.0  0.371127  \n",
      "\n",
      "[176 rows x 4 columns]\n",
      "Average off by (MAE): 0.563574\n",
      "Accuracy (within ±0.25): 0.3693181818181818\n",
      "Accuracy (within ±0.5): 0.5738636363636364\n",
      "R²: 0.7552772760391235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "prediction_df = pd.DataFrame({\n",
    "    \"review\": test_df[\"review\"].values,\n",
    "    \"predicted_rating\": predictions,\n",
    "    \"true_rating\": true\n",
    "})\n",
    "\n",
    "# how far off each prediction is\n",
    "prediction_df[\"off_by\"] = (\n",
    "    prediction_df[\"predicted_rating\"] - prediction_df[\"true_rating\"]\n",
    ").abs()\n",
    "\n",
    "# average off by (MAE)\n",
    "avg_off_by = prediction_df[\"off_by\"].mean()\n",
    "\n",
    "# accuracy thresholds\n",
    "acc_025 = (prediction_df[\"off_by\"] <= 0.25).mean()\n",
    "acc_05  = (prediction_df[\"off_by\"] <= 0.5).mean()\n",
    "\n",
    "# R^2\n",
    "r2 = r2_score(prediction_df[\"true_rating\"], prediction_df[\"predicted_rating\"])\n",
    "\n",
    "print(prediction_df)\n",
    "print(\"Average off by (MAE):\", avg_off_by)\n",
    "print(\"Accuracy (within ±0.25):\", acc_025)\n",
    "print(\"Accuracy (within ±0.5):\", acc_05)\n",
    "print(\"R²:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
